{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempting to initialise camera...\n",
      "CAMERA READY\n"
     ]
    }
   ],
   "source": [
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "\n",
    "#use opencv to covert the depth image to RGB image for displaying purpose\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#multi-threading is used to capture the image in real time performance\n",
    "import threading\n",
    "\n",
    "class Camera(SingletonConfigurable):\n",
    "    #this changing of this value will be captured by traitlets\n",
    "    frame = traitlets.Any()\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"attempting to initialise camera...\")\n",
    "        super(Camera, self).__init__()\n",
    "        \n",
    "        #create the sensor pipeline and config.\n",
    "        self.video_capture = cv2.VideoCapture(-1)\n",
    "        \n",
    "        #set resolution for the color camera\n",
    "        self.width = 640\n",
    "        self.height = 480\n",
    "        self.fps = 30\n",
    "\n",
    "        #flag to control the thread\n",
    "        self.thread_runnning_flag = False \n",
    "\n",
    "        self.ready = True\n",
    "        \n",
    "        #start capture the first color image\n",
    "        frame_success, frame = self.video_capture.read()\n",
    "        self.frame = frame\n",
    "        \n",
    "    def _capture_frames(self):\n",
    "        while(self.thread_runnning_flag==True): #continue until the thread_runnning_flag is set to be False\n",
    "            frame_success, frame = self.video_capture.read()\n",
    "            self.frame = frame\n",
    "    \n",
    "    def start(self): #start the data capture thread\n",
    "        if self.thread_runnning_flag == False: #only process if no thread is running yet\n",
    "            self.thread_runnning_flag=True #flag to control the operation of the _capture_frames function\n",
    "            self.thread = threading.Thread(target=self._capture_frames) #link thread with the function\n",
    "            self.thread.start() #start the thread\n",
    "\n",
    "    def stop(self): #stop the data capture thread\n",
    "        if self.thread_runnning_flag == True:\n",
    "            self.thread_runnning_flag = False #exit the while loop in the _capture_frames\n",
    "            self.thread.join() #wait the exiting of the thread\n",
    "\n",
    "#create a camera object\n",
    "camera = Camera.instance()\n",
    "camera.start() # start capturing the data\n",
    "if(camera.ready):\n",
    "    print(\"CAMERA READY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "from SixDRepNet import SixDRepNet\n",
    "\n",
    "face_detector = MTCNN()\n",
    "pose_detector = SixDRepNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "def bgr8_to_jpeg(value):#convert numpy array to jpeg coded data for displaying \n",
    "    return bytes(cv2.imencode('.jpg',value)[1])\n",
    "\n",
    "def resize_with_padding(image,target_size):\n",
    "    old_size= image.shape[:2]\n",
    "    print(old_size)\n",
    "    ratio = float(target_size) / max(old_size)\n",
    "    new_dim = (int(old_size[1] * ratio),int(old_size[0] * ratio))\n",
    "    print(new_dim)\n",
    "\n",
    "    image = cv2.resize(image, new_dim)\n",
    "\n",
    "    return image\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=512, height=512)\n",
    "label_widget = widgets.Label(value=\"default\")\n",
    "display(image_widget,label_widget)\n",
    "\n",
    "def processing(change):\n",
    "    frame = change[\"new\"]\n",
    "\n",
    "    face_start = time.time()\n",
    "    detection = face_detector.detect_faces(frame)\n",
    "    face_duration = time.time() - face_start\n",
    "    for face in detection:\n",
    "        bbox = face[\"box\"]\n",
    "        # create raw bounding box in blue\n",
    "        frame = cv2.rectangle(frame,\n",
    "        (bbox[0],bbox[1]),\n",
    "        (bbox[0] + bbox[2],bbox[1] + bbox[3]),\n",
    "        (255,127,0),\n",
    "        2)\n",
    "\n",
    "        # create square centered bounding box in orange\n",
    "\n",
    "        box_size = max(bbox[2:4])\n",
    "        top_left = (int(bbox[0] + (bbox[2]/2) - (box_size/2)),int(bbox[1] + (bbox[3]/2) - (box_size/2)))\n",
    "        \n",
    "        frame = cv2.rectangle(frame,\n",
    "        top_left,\n",
    "        (top_left[0] + box_size,top_left[1] + box_size),\n",
    "        (0,127,255),\n",
    "        2)\n",
    "\n",
    "        cropped = frame[top_left[1]:top_left[1]+box_size,top_left[0]:top_left[0]+box_size]\n",
    "\n",
    "        pose_start = time.time()\n",
    "        pitch, yaw, roll = pose_detector.predict(cropped)\n",
    "        pose_duration = time.time() - pose_start()\n",
    "        pose_detector.draw_axis(frame, yaw, pitch, roll,int(top_left[0] + box_size/2),int(top_left[1] + box_size/2))\n",
    "\n",
    "        total_duration = time.time()-face_start\n",
    "\n",
    "        image_widget.value = bgr8_to_jpeg(frame)\n",
    "\n",
    "        '''\n",
    "        label_widget.value = \"\"\"\n",
    "        face: {:.2f}s\n",
    "        pose: {:.2f}s\n",
    "        total: {:.2f}s\n",
    "        \"\"\".format(face_duration,pose_duration,total_duration)\n",
    "        '''\n",
    "\n",
    "camera.observe(processing,names=\"frame\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
